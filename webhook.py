from flask import Flask, request, jsonify
import os
from openai import OpenAI
import json

app = Flask(__name__)

# è¨­ç½® OpenAI API å¯†é‘°
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

if client.api_key:
    print("âœ… æˆåŠŸæŠ“åˆ° OPENAI_API_KEY:", client.api_key[:5] + "...")
else:
    print("âŒ æ²’æœ‰æ‰¾åˆ° OPENAI_API_KEY")

# è¼‰å…¥ TYPE å’Œé€£çµçš„å°æ‡‰é—œä¿‚
try:
    with open("links.json", "r", encoding="utf-8") as f:
        type_links = json.load(f)
except UnicodeDecodeError as e:
    print(f"è®€å– links.json æ™‚ç™¼ç”Ÿç·¨ç¢¼éŒ¯èª¤ï¼š{e}")
    type_links = {}

# è¼‰å…¥é…ç®¡è©¦å£“è¦ç¯„ JSON
try:
    with open("piping_specification.json", "r", encoding="utf-8") as f:
        piping_spec = json.load(f)
except FileNotFoundError:
    piping_specification = {}
    print("âŒ ç„¡æ³•æ‰¾åˆ°é…ç®¡è©¦å£“è¦ç¯„çš„ JSON æª”æ¡ˆã€‚")

def search_piping_spec(question):
    question_keywords = set(question.replace("\u3000", " ").replace(" ", "").lower())
    matched_sections = []
    matched_titles = []
    for chapter, data in piping_spec.items():
        title = data.get("title", "")
        content = data.get("content", {})
        for sec_num, sec_text in content.items():
            sec_text_clean = sec_text.replace("\u3000", " ").replace(" ", "").lower()
            if any(word in sec_text_clean for word in question_keywords):
                matched_sections.append(sec_text)
                matched_titles.append(f"ç¬¬{chapter}ç«  {title} - {sec_num}")
    return "\n\n".join(matched_sections[:3]), matched_titles, len(matched_sections)

@app.route("/webhook", methods=["POST"])
def webhook():
    try:
        req = request.get_json()
        query_result = req.get("queryResult", {})
        parameters = query_result.get("parameters", {})
        for context in query_result.get("outputContexts", []):
            if context.get("name", "").endswith("/contexts/query-followup"):
                context_params = context.get("parameters", {})
                parameters.setdefault("category", context_params.get("category", ""))
                parameters.setdefault("spec_type", context_params.get("spec_type", ""))
                parameters.setdefault("TYPE", context_params.get("type", ""))

        session = req.get("session", "")
        intent = query_result.get("intent", {}).get("displayName", "")
        user_query = query_result.get("queryText", "")  # æå–ä½¿ç”¨è€…çš„åŸå§‹è¼¸å…¥
    except Exception as e:
        return jsonify({"fulfillmentText": "ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"})

    # å¦‚æœæ˜¯ Default Fallback Intent
    if intent == "Default Fallback Intent":
        spec_summary, matched_titles, total_matches = search_piping_spec(user_query)
        if spec_summary:
            reference = "ï¼›å»ºè­°åƒè€ƒé…ç®¡å…±åŒè¦ç¯„ç« ç¯€ï¼š" + "ã€".join(matched_titles) if matched_titles else ""
            more_hint = "\nğŸ”” å°šæœ‰æ›´å¤šç›¸é—œç« ç¯€ï¼Œå»ºè­°è©³é–±å®Œæ•´è¦ç¯„ã€‚" if total_matches > 3 else ""
            reply = f"æ ¹æ“šé…ç®¡è¦ç¯„è³‡æ–™ï¼Œæ‰¾åˆ°ç›¸é—œå…§å®¹ï¼š\n{spec_summary}\n{reference}{more_hint}"
        else:
            # æ‰¾ä¸åˆ°ï¼Œæ‰ç”¨ ChatGPT å›ç­”
            try:
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯é…ç®¡è¨­è¨ˆå°ˆå®¶ï¼Œä¸å›ç­”èˆ‡é…ç®¡ç„¡é—œçš„è¨Šæ¯ã€‚"},
                        {"role": "user", "content": "è«‹ç°¡çŸ­å›ç­”ï¼š" + user_query}
                    ],
                    max_tokens=150,
                    temperature=0.2,
                    top_p=0.8
                )
                reply = response.choices[0].message.content.strip()
            except Exception as e:
                reply = "æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•è™•ç†æ‚¨çš„è«‹æ±‚ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

        return jsonify({
            "fulfillmentText": reply
        })
    # å¦‚æœä¸æ˜¯ Default Fallback Intentï¼ŒåŸ·è¡Œå…¶ä»–é‚è¼¯
    category = parameters.get("category", "")
    spec_type = parameters.get("spec_type", "")
    type_key = parameters.get("TYPE", "").upper()

    if category == "æ²¹æ¼†":
        if spec_type == "å¡‘åŒ–":
            reply = "é€™æ˜¯æ²¹æ¼†å¡‘åŒ–è¦ç¯„çš„ä¸‹è¼‰é€£çµï¼š\nhttps://tinyurl.com/yp59mpat"
        elif spec_type == "ä¼æ¥­":
            reply = "é€™æ˜¯æ²¹æ¼†ä¼æ¥­è¦ç¯„çš„ä¸‹è¼‰é€£çµï¼š\nhttps://tinyurl.com/c73ajvpt"
        else:
            reply = "è«‹å•æ˜¯è¦æŸ¥è©¢æ²¹æ¼†çš„ã€Œå¡‘åŒ–ã€é‚„æ˜¯ã€Œä¼æ¥­ã€è¦ç¯„ï¼Ÿ"
    elif category == "ç®¡æ”¯æ’":
        if spec_type == "å¡‘åŒ–":
            reply = "é€™æ˜¯ç®¡æ”¯æ’å¡‘åŒ–è¦ç¯„çš„ä¸‹è¼‰é€£çµï¼š\nhttps://tinyurl.com/5vk67ywh"
        elif spec_type == "ä¼æ¥­":
            reply = "é€™æ˜¯ç®¡æ”¯æ’ä¼æ¥­è¦ç¯„çš„ä¸‹è¼‰é€£çµï¼š\nhttps://1drv.ms/b/c/c2f6a4a69f694f7a/ERaG7Grpi7RLhLySygar-E0BqPzegJZTQK19aBUs01C55g?e=c9cAOS"
        elif "TYPE" in type_key.upper():
            if type_key.upper() in type_links:
                reply = f"é€™æ˜¯ç®¡æ”¯æ’ {type_key} çš„ä¸‹è¼‰é€£çµï¼š\n{type_links[type_key.upper()]}"
            else:
                reply = "è«‹æä¾›æœ‰æ•ˆçš„ TYPEï¼ˆä¾‹å¦‚ TYPE01 ~ TYPE140ï¼‰ã€‚"
        else:
            reply = "è«‹å•æ˜¯è¦æŸ¥è©¢ç®¡æ”¯æ’çš„ã€Œå¡‘åŒ–ã€é‚„æ˜¯ã€Œä¼æ¥­ã€è¦ç¯„ï¼Ÿ"   
    else:
        reply = "è«‹æä¾›æœ‰æ•ˆçš„é¡åˆ¥ï¼ˆä¾‹å¦‚ ç®¡æ”¯æ’ æˆ– æ²¹æ¼†ï¼‰ã€‚"

    return jsonify({
        "fulfillmentText": reply,
        "outputContexts": [
            {
                "name": f"{session}/contexts/query-followup",
                "lifespanCount": 5,
                "parameters": {
                    "category": category,
                    "spec_type": spec_type,
                    "type": type_key
                }
            }
        ]
    })

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    app.run(host="0.0.0.0", port=port)
