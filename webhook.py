from flask import Flask, request, jsonify
from fuzzywuzzy import fuzz
import os
from openai import OpenAI
import json
import re
from datetime import datetime, timedelta

# å„²å­˜ä½¿ç”¨è€…å°è©±æ­·å²ï¼Œæ ¼å¼ç‚º {session_id: {"messages": [...], "last_seen": datetime}}
session_histories = {}
MAX_HISTORY = 5  # æœ€å¤šç´€éŒ„ 5 è¼ªï¼ˆuser + assistantï¼‰
SESSION_TIMEOUT = timedelta(minutes=5)

app = Flask(__name__)

# è¨­ç½® OpenAI API å¯†é‘°
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

if client.api_key:
    print("âœ… æˆåŠŸæŠ“åˆ° OPENAI_API_KEY:", client.api_key[:5] + "...")
else:
    print("âŒ æ²’æœ‰æ‰¾åˆ° OPENAI_API_KEY")

# è¼‰å…¥ TYPE å’Œé€£çµçš„å°æ‡‰é—œä¿‚
try:
    with open("links.json", "r", encoding="utf-8") as f:
        type_links = json.load(f)
except UnicodeDecodeError as e:
    print(f"è®€å– links.json æ™‚ç™¼ç”Ÿç·¨ç¢¼éŒ¯èª¤ï¼š{e}")
    type_links = {}

# è¼‰å…¥é…ç®¡è©¦å£“è¦ç¯„ JSON
try:
    with open("piping_specification.json", "r", encoding="utf-8") as f:
        piping_specification = json.load(f)
except FileNotFoundError:
    piping_specification = {}
    print("âŒ ç„¡æ³•æ‰¾åˆ°é…ç®¡è¦ç¯„ JSON æª”æ¡ˆã€‚")

try:
    with open("piping_heat_treatment.json", "r", encoding="utf-8") as f:
        piping_heat_treatment = json.load(f)
except FileNotFoundError:
    piping_heat_treatment = {}
    print("âŒ ç„¡æ³•æ‰¾åˆ°ç†±è™•ç†è¦ç¯„ JSON æª”æ¡ˆã€‚")

#å•é¡Œä¸­æ–‡è½‰è‹±æ–‡
def translate_to_english(query):
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "è«‹å°‡ä¸‹é¢çš„ä¸­æ–‡å·¥ç¨‹å•é¡Œç¿»è­¯ç‚ºç°¡æ½”ç²¾ç¢ºçš„è‹±æ–‡ï¼Œä¾›è³‡æ–™æ¯”å°ä½¿ç”¨ã€‚"},
            {"role": "user", "content": query}
        ],
        temperature=0.2
    )
    return response.choices[0].message.content.strip()


""" def search_piping_spec(question, spec_data, keywords):
    question_cleaned = re.sub(r"\s+", "", question).lower()
    
    matched_sections = []
    matched_titles = []
    total_matches = 0

    for chapter, data in spec_data.items():
        title = data.get("title", "")
        content = data.get("content", {})

        chapter_matched = any(keyword in title.lower() for keyword in keywords)

        if not chapter_matched:
            for sec_num, sec_text in content.items():
                sec_text_clean = re.sub(r"\s+", "", sec_text).lower()
                if question_cleaned in sec_text_clean:
                    chapter_matched = True
                    break

        if chapter_matched:
            matched_sections.append(f"ç¬¬{chapter}ç«  {title}")
            matched_titles.append(f"ç¬¬{chapter}ç«  {title}")
            total_matches += 1

            sorted_content = sorted(content.items(), key=lambda x: x[0])
            for sec_num, sec_text in sorted_content:
                matched_sections.append(f"{sec_num} {sec_text}")
                matched_titles.append(f"ç¬¬{chapter}ç«  {title} - {sec_num}")
                total_matches += 1

    if matched_sections:
        summary = "\n".join(matched_sections)
        return summary, matched_titles, total_matches

    return "", [], 0 """

def search_piping_spec(question, spec_data, keywords, threshold=70):
    question_cleaned = re.sub(r"\s+", "", question).lower()

    matched_summaries = []
    matched_details = {}
    total_matches = 0

    for chapter, data in spec_data.items():
        title = data.get("title", "")
        content = data.get("content", {})

        for sec_num, sec_text in content.items():
            text_clean = re.sub(r"\s+", "", sec_text).lower()

            # æ¨¡ç³Šæ¯”å°åˆ†æ•¸
            score = fuzz.partial_ratio(question_cleaned, text_clean)

            if score >= threshold:
                key = f"ç¬¬{chapter}ç«  {title} - {sec_num}"
                matched_summaries.append(key)
                matched_details[key] = sec_text
                total_matches += 1

    if matched_summaries:
        summary = "\n".join([f"{i+1}. {s}" for i, s in enumerate(matched_summaries)])
        return summary, matched_details, total_matches

    return "æŸ¥ç„¡ç›¸é—œå…§å®¹ã€‚", {}, 0


""" # def generate_spec_reply(user_query, spec_data, spec_type_desc):
#     keywords = {"è¦ç¯„", "è³‡æ–™", "æ¨™æº–åœ–", "æŸ¥è©¢", "æˆ‘è¦æŸ¥", "æŸ¥"}  # å®šç¾©é—œéµå­—
#     summary, matched_titles, total_matches = search_piping_spec(user_query, spec_data, keywords)
#     if total_matches == 0:
#         english_query = translate_to_english(user_query)  # ç¿»è­¯æˆè‹±æ–‡
#         summary, matched_titles, total_matches = search_piping_spec(english_query, spec_data, keywords)

#     if total_matches > 0:
#         if len(summary) > 500:
#             reply = f"æ ¹æ“šã€Š{spec_type_desc}ã€‹ï¼Œæ‰¾åˆ°ç›¸é—œå…§å®¹ï¼ˆå·²æˆªå–ï¼‰ï¼š\n{summary[:500]}...\nğŸ”” å…§å®¹éé•·ï¼Œè«‹æŸ¥é–±å®Œæ•´è¦ç¯„ã€‚"
#         else:
#             reply = f"æ ¹æ“šã€Š{spec_type_desc}ã€‹ï¼Œæ‰¾åˆ°ç›¸é—œå…§å®¹ï¼š\n{summary}"
#     else:
#         try:
#             print("ğŸ” å‘¼å« GPT å›ç­”...")
#             response = client.chat.completions.create(
#                 model="gpt-3.5-turbo",
#                 messages=[
#                     {"role": "system", "content": "ä½ æ˜¯é…ç®¡è¨­è¨ˆå°ˆå®¶ï¼Œåªå›ç­”èˆ‡é…ç®¡è¦ç¯„ç›¸é—œçš„å•é¡Œã€‚"},
#                     {"role": "user", "content": user_query}
#                 ],
#                 max_tokens=500,
#                 temperature=0.2,
#                 top_p=0.8
#             )
#             reply = response.choices[0].message.content.strip()
#         except Exception as e:
#             print("âŒ GPT å‘¼å«å¤±æ•—:", e)
#             reply = "æŠ±æ­‰ï¼Œç›®å‰ç„¡æ³•è™•ç†æ‚¨çš„è«‹æ±‚ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

#     return jsonify({
#         "fulfillmentText": reply
#     })
 """




#LINE æŒ‰éˆ•ç¨‹å¼
def payload_with_buttons(text, options):    
    return {
        "payload": {
            "line": {
                "type": "template",
                "altText": text,
                "template": {
                    "type": "buttons",
                    "text": text,
                    "actions": [
                        {"type": "message", "label": opt, "text": opt} for opt in options
                    ]
                }
            }
        }
    }

def query_download_link(category, source):
    links = {
        ("ç®¡æ”¯æ’", "å¡‘åŒ–"): "https://tinyurl.com/5vk67ywh",
        ("ç®¡æ”¯æ’", "ä¼æ¥­"): "https://tinyurl.com/msxhmnha",
        ("ä¿æº«", "ä¼æ¥­"): "https://tinyurl.com/2s4cb5cn",
        ("ä¿æº«", "å¡‘åŒ–"): "ä¿æº«è¦ç¯„è«‹åƒè€ƒä¼æ¥­è¦ç¯„\nhttps://tinyurl.com/2s4cb5cn"
    }
    return links.get((category, source), "æŸ¥ç„¡å°æ‡‰çš„ä¸‹è¼‰é€£çµ")

    # å®šç¾© categories_mapï¼Œé¡ä¼¼ actions_map çš„çµæ§‹
category_keywords = {
        "ç®¡æ”¯æ’": ["ç®¡æ”¯æ’", "æ”¯æ’", "ç®¡é“æ”¯æ’","PIPING SUPPORT","SUPPORT"],
        "ä¿æº«": ["ä¿æº«", "insulation", "å²©æ£‰", "æ°£è† é«”", "ä¿æº«æ", "PIR"],
    } 
action_keywords = {
    "è©¢å•å…§å®¹": ["æŸ¥è©¢", "æŸ¥", "è©¢å•", "æ‰¾"],
    "ä¸‹è¼‰": ["ä¸‹è¼‰", "çµ¦æˆ‘", "æä¾›"],}
sources = ["ä¼æ¥­", "å¡‘åŒ–"]
categories_map = {k: v for v, keys in category_keywords.items() for k in keys}
actions_map = {k: v for v, keys in action_keywords.items() for k in keys}


def extract_from_query(text):
    found = {"category": "", "source": "", "action": ""}

        # æª¢æŸ¥æ˜¯å¦æœ‰åŒ¹é…çš„ category
    for keyword, category in categories_map.items():
        if keyword in text:
            found["category"] = category
            break
    for s in sources:
        if s in text:
            found["source"] = s
            break
    if any(word in text for word in action_keywords["ä¸‹è¼‰"]):
        found["action"] = "ä¸‹è¼‰"
    elif any(word in text for word in action_keywords["è©¢å•å…§å®¹"]):
        found["action"] = "è©¢å•å…§å®¹"

    return found
       # è®€å– context ä¸­çš„åƒæ•¸

@app.route("/webhook", methods=["POST"])
def webhook():
    req = request.get_json()
    if not isinstance(req, dict):
        print(f"âŒ éŒ¯èª¤ï¼šreq ä¸æ˜¯å­—å…¸ï¼Œè€Œæ˜¯ {type(req)}")
        return jsonify({"fulfillmentText": "è«‹æ±‚æ ¼å¼éŒ¯èª¤ï¼Œè«‹ç¢ºä¿ Content-Type ç‚º application/jsonã€‚"}) 

    query_result = req.get("queryResult", {})
    user_query = query_result.get("queryText", "")
    session = req.get("session", "")
    intent = req.get("queryResult", {}).get("intent", {}).get("displayName", "")

    # è®€å– context ä¸­çš„åƒæ•¸
    context_params = {}
    for context in req.get("queryResult", {}).get("outputContexts", []):
        if "spec-context" in context.get("name", ""):
            context_params = context.get("parameters", {})

    def output_context(params):
        if not params or params.get("await_spec_selection") is False:
            # æ¸…é™¤ä¸Šä¸‹æ–‡
            return [{
                "name": f"{session}/contexts/spec-context",
                "lifespanCount": 0,  # è¨­ç½® lifespanCount ç‚º 0 æ¸…é™¤ä¸Šä¸‹æ–‡
                "parameters": {}
            }]
        else:
            # ä¿ç•™ä¸Šä¸‹æ–‡
            return [{
                "name": f"{session}/contexts/spec-context",
                "lifespanCount": 5,  # è¨­ç½®ä¸Šä¸‹æ–‡çš„æœ‰æ•ˆæœŸ
                "parameters": params
            }]
   
    def generate_spec_reply(user_query, spec_data, spec_type_desc):
        keywords = {"è¦ç¯„", "è³‡æ–™", "æ¨™æº–åœ–", "æŸ¥è©¢", "æˆ‘è¦æŸ¥", "æŸ¥"}

        summary, matched_details, total_matches = search_piping_spec(user_query, spec_data, keywords)

        if total_matches == 0:
            english_query = translate_to_english(user_query)
            summary, matched_details, total_matches = search_piping_spec(english_query, spec_data, keywords)

        if total_matches > 0:
            reply = f"æ ¹æ“šã€Š{spec_type_desc}ã€‹ï¼Œæ‰¾åˆ° {total_matches} ç­†ç›¸é—œå…§å®¹ï¼š\n{summary}\nè«‹è¼¸å…¥å°æ‡‰çš„é …ç›®ç·¨è™ŸæŸ¥çœ‹è©³ç´°å…§å®¹ï¼ˆä¾‹å¦‚è¼¸å…¥ 1ï¼‰"
            
            context = {
                "await_spec_selection": True,
                "spec_options": list(matched_details.items())
            }

            return {
                "fulfillmentText": reply,
                "outputContexts": output_context({
                    "await_spec_selection": True,
                    "spec_options": list(matched_details.items())
                })
            }
        else:
            try:
                print("ğŸ” å‘¼å« GPT å›ç­”...")
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯é…ç®¡è¨­è¨ˆå°ˆå®¶ï¼Œåªå›ç­”èˆ‡é…ç®¡è¦ç¯„ç›¸é—œçš„å•é¡Œã€‚"},
                        {"role": "user", "content": user_query}
                    ],
                    max_tokens=350,
                    temperature=0.4,
                    top_p=1
                )
                reply = response.choices[0].message.content.strip()
            except Exception as e:
                print("âŒ GPT å‘¼å«å¤±æ•—:", e)
                reply = "æŠ±æ­‰ï¼Œç›®å‰ç„¡æ³•è™•ç†æ‚¨çš„è«‹æ±‚ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

            return {
                "fulfillmentText": reply
            }
    
    if context_params.get("await_spec_selection"):
        user_choice = user_query.strip()
        spec_items = context_params.get("spec_options", [])

        if not spec_items:
            return jsonify({
                "fulfillmentText": "ä¸Šä¸‹æ–‡å·²éæœŸï¼Œè«‹é‡æ–°æŸ¥è©¢ã€‚",
                "outputContexts": output_context({})
            })

        if user_choice.isdigit():
            index = int(user_choice) - 1
            if 0 <= index < len(spec_items):
                title, content = spec_items[index]

                # åˆ¤æ–·æ˜¯å¦è¶…é 300 å­—ï¼Œè‹¥è¶…éå‰‡å‘¼å« GPT é€²è¡Œé‡é»æ‘˜è¦
                if len(content) > 300:
                    try:
                        print("ğŸ“„ å…§å®¹è¶…é 300 å­—ï¼Œå‘¼å« GPT ç”Ÿæˆæ‘˜è¦ä¸­...")
                        response = client.chat.completions.create(
                            model="gpt-3.5-turbo",
                            messages=[
                                {"role": "system", "content": "ä½ æ˜¯é…ç®¡è¨­è¨ˆå°ˆå®¶ï¼Œè«‹å°‡ä»¥ä¸‹é…ç®¡è¦ç¯„å…§å®¹é€²è¡Œæ¢åˆ—å¼é‡é»æ•´ç†ï¼Œä¿ç•™åŸæ„ä¸¦æ¸…æ¥šç°¡æ˜ã€‚"},
                                {"role": "user", "content": content}
                            ],
                            max_tokens=400,
                            temperature=0.3,
                            top_p=0.8
                        )
                        summary = response.choices[0].message.content.strip()
                        reply_text = f"ğŸ“˜ æ‚¨é¸æ“‡çš„æ˜¯ï¼š{title}\n\nğŸ“Œ **é‡é»æ•´ç†ï¼š**\n{summary}\n\nğŸ“„ **åŸå§‹å…§å®¹å¦‚ä¸‹ï¼š**\n{content}"
                    except Exception as e:
                        print("âŒ GPT æ‘˜è¦å¤±æ•—:", e)
                        reply_text = f"ğŸ“˜ æ‚¨é¸æ“‡çš„æ˜¯ï¼š{title}\nå…§å®¹å¦‚ä¸‹ï¼š\n{content}"
                else:
                    reply_text = f"ğŸ“˜ æ‚¨é¸æ“‡çš„æ˜¯ï¼š{title}\nå…§å®¹å¦‚ä¸‹ï¼š\n{content}"

                return jsonify({
                    "fulfillmentText": reply_text,
                    "outputContexts": output_context({})  # æ¸…é™¤ä¸Šä¸‹æ–‡
                })
            else:
                return jsonify({
                    "fulfillmentText": f"è«‹è¼¸å…¥æœ‰æ•ˆçš„æ•¸å­—ï¼ˆä¾‹å¦‚ 1~{len(spec_items)}ï¼‰"
                })
        else:
            return jsonify({
                "fulfillmentText": "è«‹è¼¸å…¥é …ç›®ç·¨è™Ÿï¼ˆä¾‹å¦‚ 1 æˆ– 2ï¼‰ï¼Œä»¥æŸ¥çœ‹è©³ç´°å…§å®¹ã€‚"
            })

    if intent == "å•Ÿå‹•ç®¡ç·šç†±è™•ç†è¦ç¯„å•ç­”æ¨¡å¼":
        return jsonify({
            "fulfillmentText": ("è«‹å•æ‚¨æƒ³è©¢å•å“ªæ®µç†±è™•ç†è¦ç¯„å…§å®¹ï¼Ÿ\nä¾‹å¦‚ï¼šé ç†±æº«åº¦ã€PWHTæº«åº¦ã€ä¿æº«æ™‚é–“ã€å†·å»æ–¹å¼ç­‰ã€‚"),
            "outputContexts": output_context({
                "await_heat_question": True,                
            })
        })
    elif intent == "è«‹è¼¸å…¥ç®¡ç·šç­‰ç´šåç¨±":
        return jsonify({
                "fulfillmentText": ("è«‹è¼¸å…¥ç®¡ç·šç­‰ç´šï¼ˆå¦‚ A012ã€B012ã€A144N ç­‰ï¼‰ä»¥æŸ¥è©¢å°æ‡‰é€£çµã€‚"),
                "outputContexts": output_context({
                "await_pipinclass_download": True,                
            })
        })

    elif intent == "ä¸‹è¼‰ç®¡ç·šç­‰ç´š":
        extracted_data = extract_from_query(user_query)
        user_query = req.get("queryResult", {}).get("queryText", "").upper()
    # æ¯”å°ï¼š1 å€‹è‹±æ–‡å­—æ¯ + 3 ä½æ•¸å­— + å¯é¸çš„è‹±æ–‡å­—æ¯ï¼ˆå¦‚ A012ã€A144Nï¼‰
        match = re.search(r"\b([A-Z]{1,2}\d{2,4}[A-Z]?)\b", user_query.upper())
        if match:
            grade_code = match.group(1)
            if grade_code in type_links:
                return jsonify({
                    "fulfillmentText": f"é€™æ˜¯ç®¡ç·šç­‰ç´š {grade_code} çš„å°æ‡‰é€£çµï¼š\n{type_links[grade_code]}"
                })
            else:
                return jsonify({
                    "fulfillmentText": f"æ‰¾ä¸åˆ°ç®¡ç·šç­‰ç´š {grade_code} çš„é€£çµï¼Œè«‹ç¢ºèªæ˜¯å¦è¼¸å…¥æ­£ç¢ºã€‚"
                })
        else:
            return jsonify({
                "fulfillmentText": "è«‹è¼¸å…¥æ­£ç¢ºçš„ç®¡ç·šç­‰ç´šï¼ˆå¦‚ A012ã€B012ã€A144N ç­‰ï¼‰ä»¥æŸ¥è©¢å°æ‡‰é€£çµã€‚"
            })
        # return jsonify({
        #     "fulfillmentText": spec_reply.get_json()["fulfillmentText"],
        #     "outputContexts": output_context({
        #         "await_heat_question": True,
        #         "await_spec_selection": True
        #     })
        #})
    # elif intent == "è©¢å•é…ç®¡å…±åŒè¦æ±‚è¦ç¯„å…§å®¹":
    #     print(f"ğŸ” Debugè©¢å•é…ç®¡å…±åŒè¦æ±‚è¦ç¯„å…§å®¹: intent={intent}, user_query={user_query}, context_params={context_params}")
    #     spec_reply = generate_spec_reply(user_query, piping_specification, "è©¢å•é…ç®¡å…±åŒè¦æ±‚è¦ç¯„å…§å®¹")
    #     return jsonify(spec_reply)
    elif intent == "å•Ÿå‹•é…ç®¡å…±åŒè¦æ±‚è¦ç¯„å•ç­”æ¨¡å¼":
        return jsonify({
            "fulfillmentText": ("è«‹å•æ‚¨æƒ³è©¢å•å“ªæ®µé…ç®¡å…±åŒè¦æ±‚è¦ç¯„å…§å®¹"),
            "outputContexts": output_context({
                "await_pipecommon_question": True,                
            })
        })

    elif intent == "æŸ¥è©¢ç®¡æ”¯æ’åŠä¿æº«è¦ç¯„":
        # çµ±ä¸€å–å¾—åƒæ•¸ï¼šå„ªå…ˆå¾ query æŠ½å‡ºï¼Œå¦å‰‡ä½¿ç”¨ context ä¸­å€¼
        extracted_data = extract_from_query(user_query)
        category = extracted_data.get("category", context_params.get("category", ""))
        source = extracted_data.get("source", context_params.get("source", ""))
        action = extracted_data.get("action", context_params.get("action", ""))

        # æª¢æŸ¥æ˜¯å¦æåˆ° TYPE ç·¨è™Ÿ
        user_query = user_query.upper()  # é å…ˆè½‰å¤§å¯«ï¼Œæé«˜æ•ˆç‡

        if "TYPE" in user_query or re.search(r"M[-\s]*\d+", user_query):
            match_type = re.search(r"(?:TY(?:PE)?)[-\s]*0*(\d{1,3}[A-Z]?)", user_query.upper())
            match_m = re.search(r"(?:ç®¡æ”¯æ’\s*)?M[-\s]*0*(\d{1,2}[A-Z]?)", user_query.upper())

            if match_type:
                type_id = match_type.group(1)
                
                # æª¢æŸ¥æ˜¯å¦æœ‰å­—æ¯å°¾ç¢¼ï¼Œä¸¦æ ¹æ“šæƒ…æ³è£œé›¶
                if type_id[-1].isalpha():
                    num_part = type_id[:-1].zfill(2) if type_id[:-1] else "00"
                    alpha_part = type_id[-1]
                    type_key = f"TYPE{num_part}{alpha_part}"
                else:
                    type_key = f"TYPE{type_id.zfill(2)}"

                if type_key in type_links:
                    return jsonify({
                        "fulfillmentText": f"é€™æ˜¯ç®¡æ”¯æ’è¦ç¯„ï¼ˆå¡‘åŒ–ï¼‰{type_key} çš„ä¸‹è¼‰é€£çµï¼š\n{type_links[type_key]}"
                    })
                else:
                    return jsonify({
                        "fulfillmentText": f"æ‰¾ä¸åˆ° {type_key} çš„å°æ‡‰é€£çµï¼Œè«‹ç¢ºèªæ˜¯å¦è¼¸å…¥æ­£ç¢ºã€‚"
                    })

            elif match_m:
                m_id = match_m.group(1)
                
                # æª¢æŸ¥æ˜¯å¦æœ‰å­—æ¯å°¾ç¢¼ï¼Œä¸¦æ ¹æ“šæƒ…æ³è£œé›¶
                if m_id[-1].isalpha():
                    num_part = m_id[:-1].zfill(2) if m_id[:-1] else "00"
                    alpha_part = m_id[-1]
                    m_key = f"M{num_part}{alpha_part}"
                else:
                    m_key = f"M{m_id.zfill(2)}"

                if m_key in type_links:
                    return jsonify({
                        "fulfillmentText": f"é€™æ˜¯ç®¡æ”¯æ’è¦ç¯„ {m_key} çš„ä¸‹è¼‰é€£çµï¼š\n{type_links[m_key]}"
                    })
                else:
                    return jsonify({
                        "fulfillmentText": f"æ‰¾ä¸åˆ° {m_key} çš„å°æ‡‰é€£çµï¼Œè«‹ç¢ºèªæ˜¯å¦è¼¸å…¥æ­£ç¢ºã€‚"
                    })

            else:
                return jsonify({
                    "fulfillmentText": "è«‹è¼¸å…¥æ­£ç¢ºçš„ç®¡æ”¯æ’å‹å¼ç·¨è™Ÿï¼ˆå¦‚ TYPE01 æˆ– M01ï¼‰ä»¥æŸ¥è©¢è¦ç¯„é€£çµã€‚"
                })

            
        print(f"ğŸ§© æŠ½å–çµæœ: category={category}, source={source}, action={action}, intent={intent}")  
        
        # âœ… åŠ å…¥è‡ªå‹•ä¸‹è¼‰æ¢ä»¶
        if action == "ä¸‹è¼‰" and category and source:
            link = query_download_link(category, source)
            return jsonify({
                "fulfillmentText": f"é€™æ˜¯ {category}ï¼ˆ{source}ï¼‰è¦ç¯„çš„ä¸‹è¼‰é€£çµï¼š\n{link}",
                "outputContexts": output_context({"category": category, "source": ""})  # æ¸…é™¤ source
            })

        keywords = {"è¦ç¯„", "è³‡æ–™", "æ¨™æº–åœ–", "æŸ¥è©¢", "æˆ‘è¦æŸ¥", "æŸ¥"}
        if any(k in user_query for k in keywords):
            if not category:
                print(f"ğŸ” Debug: category={category}, source={source}, action={action}")
                return jsonify({
                    "fulfillmentMessages": [payload_with_buttons("è«‹é¸æ“‡è¦ç¯„é¡åˆ¥", ["æŸ¥ç®¡æ”¯æ’","æŸ¥ä¿æº«"])],
                    "outputContexts": [{
                        "name": f"{session}/contexts/spec-context",
                        "lifespanCount": 5,
                        "parameters": {"source": source, "action": action}
                    }]
                })
            elif not source:
                return jsonify({
                    "fulfillmentMessages": [payload_with_buttons(f"{category}ï¼šè«‹é¸æ“‡ä¾†æºé¡å‹", ["ä¼æ¥­", "å¡‘åŒ–"])],
                    "outputContexts": [{
                        "name": f"{session}/contexts/spec-context",
                        "lifespanCount": 5,
                        "parameters": {"category": category, "action": action}
                    }]
                })
            else:
                return jsonify({
                    "fulfillmentMessages": [
                        payload_with_buttons(
                            f"{category}ï¼ˆ{user_query}ï¼‰ï¼šè«‹é¸æ“‡ä¸‹ä¸€æ­¥",
                            [f"ä¸‹è¼‰{category}ï¼ˆ{user_query}ï¼‰", "è©¢å•å…§å®¹"]
                        )
                    ],
                    "outputContexts": [{
                        "name": f"{session}/contexts/spec-context",
                        "lifespanCount": 5,
                        "parameters": {"category": category, "source": source}
                    }]  
                })
        if user_query in ["ä¼æ¥­", "å¡‘åŒ–"]:
            # å¾ä¸Šä¸‹æ–‡ä¸­æå– category å’Œ action
            remembered_category = context_params.get("category", "")
            remembered_action = context_params.get("action", "")
            
            print(f"ğŸ” Debug: remembered_category={remembered_category}, remembered_action={remembered_action}, user_query={user_query}")
            
            if remembered_category:
                if remembered_action == "ä¸‹è¼‰":
                    link = query_download_link(remembered_category, user_query)
                    return jsonify({
                        "fulfillmentText": f"é€™æ˜¯ {remembered_category}ï¼ˆ{user_query}ï¼‰è¦ç¯„çš„ä¸‹è¼‰é€£çµï¼š\n{link}",
                        "outputContexts": [{
                            "name": f"{session}/contexts/spec-context",
                            "lifespanCount": 5,
                            "parameters": {
                                "category": remembered_category,
                                "source": user_query,
                                "action": remembered_action
                            }
                        }]
                    })
                else:
                    return jsonify({
                        "fulfillmentMessages": [
                            payload_with_buttons(
                                f"{remembered_category}ï¼ˆ{user_query}ï¼‰ï¼šè«‹é¸æ“‡ä¸‹ä¸€æ­¥",
                                [f"ä¸‹è¼‰{remembered_category}ï¼ˆ{user_query}ï¼‰", "è©¢å•å…§å®¹"]
                            )
                        ],
                        "outputContexts": [{
                            "name": f"{session}/contexts/spec-context",
                            "lifespanCount": 5,
                            "parameters": {
                                "category": remembered_category,
                                "source": user_query,
                                "action": remembered_action
                            }
                        }]
                    })
            else:
                return jsonify({
                    "fulfillmentMessages": [payload_with_buttons("è«‹é¸æ“‡è¦ç¯„é¡åˆ¥", ["ç®¡æ”¯æ’", "ä¿æº«"])],
                    "outputContexts": output_context({"source": user_query, "action": remembered_action})
                })


        if user_query == "è©¢å•å…§å®¹":
            # æ¸…é™¤ source
                return jsonify({
                    "fulfillmentText": "è«‹å•æ‚¨æƒ³è©¢å•å“ªæ®µè¦ç¯„å…§å®¹ï¼Ÿä¾‹å¦‚ï¼šæ¸¬è©¦ã€æ¸…æ´—ã€å£“åŠ›ç­‰ã€‚",
                    "outputContexts": output_context({"category": category, "source": ""})  # æ¸…é™¤ source
                })  
        
        return jsonify({
        "fulfillmentMessages": [payload_with_buttons("è«‹é¸æ“‡è¦ç¯„é¡åˆ¥-", ["æŸ¥è©¢ç®¡æ”¯æ’", "æŸ¥è©¢ä¿æº«"])],
        "outputContexts": output_context({})
    })

    elif intent == "è©¢å•ç®¡ç·šç­‰ç´šå•é¡Œå›ç­”":
        try:
            print("ğŸ’¬ ç”± GPT å›ç­”è¦ç¯„å…§å®¹...")
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",  # å»ºè­°ä½¿ç”¨ gpt-4 æˆ– gpt-4-turbo
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯é…ç®¡è¨­è¨ˆå°ˆå®¶ï¼Œåªå›ç­”èˆ‡å·¥ç¨‹è¦ç¯„ã€æ¨™æº–åœ–æˆ–æ–½å·¥æ¨™æº–ç›¸é—œçš„å•é¡Œï¼Œè«‹æ ¹æ“šä½¿ç”¨è€…çš„å•é¡Œæä¾›æ¸…æ¥šç°¡æ½”çš„å›ç­”ã€‚"},
                    {"role": "user", "content": user_query}
                ],
                max_tokens=400,
                temperature=0.4,
                top_p=1
            )
            reply = response.choices[0].message.content.strip()
            return jsonify({
            "fulfillmentText": reply,
            "outputContexts": output_context({"await_pipeclass_question": True})
        })
        except Exception as e:
            print("âŒ GPT å‘¼å«å¤±æ•—:", e)
            reply = "æŠ±æ­‰ï¼Œç›®å‰ç„¡æ³•è™•ç†æ‚¨çš„è«‹æ±‚ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

        return jsonify({
            "fulfillmentText": reply,
            "outputContexts": output_context({"await_pipeclass_question": True})
        })     
   


    elif intent == "Default Fallback Intent":

        # è®€å–æ­·å²ï¼ˆè‹¥è¶…é SESSION_TIMEOUT å‰‡é‡ç½®ï¼‰
        now = datetime.now()
        session_data = session_histories.get(session, {"messages": [], "last_seen": now})
        if now - session_data["last_seen"] > SESSION_TIMEOUT:
            session_data["messages"] = []

        # âœ… æª¢æŸ¥æ˜¯å¦è¦é‡è¨­å°è©±
        if user_query.strip() in ["é‡æ–°é–‹å§‹", "reset", "é‡è¨­å°è©±", "é‡æ–°ä¾†"]:
            session_data["messages"] = []
            session_data["last_seen"] = now
            session_histories[session] = session_data

            reply = {
                "fulfillmentText": "âœ… å°è©±å·²é‡ç½®ï¼Œè«‹é‡æ–°è¼¸å…¥æ‚¨æƒ³æŸ¥è©¢çš„è¦ç¯„æˆ–å•é¡Œã€‚",
            }
            return jsonify(reply)

        history = session_data["messages"]

        # åŠ å…¥ä½¿ç”¨è€…è¼¸å…¥
        history.append({"role": "user", "content": user_query})

        # é™åˆ¶æ­·å²é•·åº¦
        if len(history) > MAX_HISTORY * 2:
            history = history[-MAX_HISTORY * 2:]

        # æ˜¯å¦éœ€è¦æé†’
        user_reminder = ""
        if len(history) >= MAX_HISTORY * 2:
            user_reminder = "âš ï¸ æ‚¨çš„å°è©±å·²è¶…é 5 è¼ªï¼Œç‚ºä¿æŒæ•ˆèƒ½ï¼Œå»ºè­°æ•´ç†å•é¡Œè«‹è¼¸å…¥é‡è¨­å°è©±ã€‚\n\n"

        session_data["messages"] = history
        session_data["last_seen"] = now
        session_histories[session] = session_data

        system_prompt = """
        ä½ æ˜¯é…ç®¡è¨­è¨ˆå°ˆå®¶ï¼Œå…·æœ‰åå¹´ä»¥ä¸Šå·¥æ¥­é…ç®¡ã€è¨­å‚™åŠé‹¼æ§‹è¨­è¨ˆç¶“é©—ï¼Œç†Ÿæ‚‰ASMEã€JISã€APIç­‰ç›¸é—œæ¨™æº–èˆ‡æ–½å·¥è¦ç¯„ã€‚
        å›ç­”æ™‚è«‹ä¿æŒå°ˆæ¥­ä¸”ç°¡æ½”æ˜ç­ï¼Œé¿å…éåº¦å†—é•·ã€‚
        å›ç­”å…§å®¹é ˆå…·é«”ä¸”æŠ€è¡“æ€§å¼·ï¼Œä¸¦ä»¥æ­£å¼ä¸”ç¦®è²Œçš„èªæ°£å›è¦†ã€‚
        å¦‚æœå•é¡Œè¶…å‡ºè¦ç¯„ç¯„åœï¼Œè«‹ç¦®è²Œå‘ŠçŸ¥ä¸¦å»ºè­°ç›¸é—œæŸ¥è©¢æ–¹å‘ã€‚
        è«‹é¿å…æä¾›èˆ‡å·¥ç¨‹è¨­è¨ˆç„¡é—œçš„è³‡è¨Šã€‚
        è«‹åœ¨å›ç­”ä¸­ç›¡é‡åŒ…å«æ¨™æº–ç·¨è™Ÿã€æ³•è¦æ¢æ–‡æˆ–æ¨™æº–åœ–å¼•ç”¨ã€‚
        è‹¥ä½¿ç”¨å°ˆæœ‰åè©ï¼Œè«‹é©ç•¶è§£é‡‹ä»¥ç¢ºä¿æ¸…æ™°æ˜“æ‡‚ã€‚
        """

        # è™•ç†ç‰¹å®šä¸Šä¸‹æ–‡é‚è¼¯ï¼ˆç†±è™•ç†ã€å…±åŒè¦ç¯„ã€ç®¡ç·šç­‰ç´šï¼‰
        if context_params.get("await_heat_question"):
            print("ğŸ”„ é‡æ–°è·¯ç”±åˆ°ç†±è™•ç†è¦ç¯„")
            spec_reply = generate_spec_reply(user_query, piping_heat_treatment, "è©¢å•ç†±è™•ç†è¦ç¯„")
            return jsonify(spec_reply)

        elif context_params.get("await_pipecommon_question"):
            print("ğŸ”„ é‡æ–°è·¯ç”±åˆ°é…ç®¡å…±åŒè¦ç¯„")
            spec_reply = generate_spec_reply(user_query, piping_specification, "è©¢å•é…ç®¡å…±åŒè¦ç¯„")
            return jsonify(spec_reply)

        elif context_params.get("await_pipinclass_download"):
            extracted_data = extract_from_query(user_query)
            user_query = req.get("queryResult", {}).get("queryText", "").upper()
        # æ¯”å°ï¼š1 å€‹è‹±æ–‡å­—æ¯ + 3 ä½æ•¸å­— + å¯é¸çš„è‹±æ–‡å­—æ¯ï¼ˆå¦‚ A012ã€A144Nï¼‰
            match = re.search(r"\b([A-Z]{1,2}\d{2,4}[A-Z]?)\b", user_query.upper())
            if match:
                grade_code = match.group(1)
                if grade_code in type_links:
                    return jsonify({
                        "fulfillmentText": f"é€™æ˜¯ç®¡ç·šç­‰ç´š {grade_code} çš„å°æ‡‰é€£çµï¼š\n{type_links[grade_code]}"
                    })
                else:
                    return jsonify({
                        "fulfillmentText": f"æ‰¾ä¸åˆ°ç®¡ç·šç­‰ç´š {grade_code} çš„é€£çµï¼Œè«‹ç¢ºèªæ˜¯å¦è¼¸å…¥æ­£ç¢ºã€‚"
                    })
            else:
                return jsonify({
                    "fulfillmentText": "è«‹è¼¸å…¥æ­£ç¢ºçš„ç®¡ç·šç­‰ç´šï¼ˆå¦‚ A012ã€B012ã€A144N ç­‰ï¼‰ä»¥æŸ¥è©¢å°æ‡‰é€£çµã€‚"
                })

        # ğŸ” è™•ç†å…¶ä»–è¦ç¯„å•é¡Œ
        elif context_params.get("await_pipeclass_question"):
            try:
                print("ğŸ’¬ ç”± GPT å›ç­”è¦ç¯„å…§å®¹...")
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_query}
                    ]+ history,
                    max_tokens=400,
                    temperature=0.3,
                    top_p=1,
                )
                reply = response.choices[0].message.content.strip()

            except Exception as e:
                print("âŒ GPT å‘¼å«å¤±æ•—:", e)
                reply = "æŠ±æ­‰ï¼Œç›®å‰ç„¡æ³•è™•ç†æ‚¨çš„è«‹æ±‚ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

            return jsonify({
                "fulfillmentText": reply
            })
        else :
            try:
                print("ğŸ’¬ ä½¿ç”¨ GPT èˆ‡å°è©±æ­·å²å›ç­”è¦ç¯„å•é¡Œ...")
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "system", "content": system_prompt}] + history,
                    max_tokens=400,
                    temperature=0.4,
                    top_p=1,                                
                    frequency_penalty=0.1,
                    presence_penalty=0,
                )
                reply = user_reminder + response.choices[0].message.content.strip()

                # å°‡ GPT å›ç­”åŠ å…¥æ­·å²
                history.append({"role": "assistant", "content": reply})
                session_data["messages"] = history
                session_data["last_seen"] = now
                session_histories[session] = session_data

            except Exception as e:
                print("âŒ GPT å‘¼å«å¤±æ•—:", e)
                reply = "æŠ±æ­‰ï¼Œç›®å‰ç„¡æ³•è™•ç†æ‚¨çš„è«‹æ±‚ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

            return jsonify({
                "fulfillmentText": reply
            })   
 
    else: 
        return generate_spec_reply(user_query, piping_specification, "ä¼æ¥­é…ç®¡å…±åŒè¦ç¯„")

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    app.run(host="0.0.0.0", port=port)

# (Removed invalid Python code)ngrok http 5000
