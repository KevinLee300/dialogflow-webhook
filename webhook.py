from flask import Flask, request, jsonify
import os
from openai import OpenAI
import json
import re

app = Flask(__name__)

# è¨­ç½® OpenAI API å¯†é‘°
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

if client.api_key:
    print("âœ… æˆåŠŸæŠ“åˆ° OPENAI_API_KEY:", client.api_key[:5] + "...")
else:
    print("âŒ æ²’æœ‰æ‰¾åˆ° OPENAI_API_KEY")

# è¼‰å…¥ TYPE å’Œé€£çµçš„å°æ‡‰é—œä¿‚
try:
    with open("links.json", "r", encoding="utf-8") as f:
        type_links = json.load(f)
except UnicodeDecodeError as e:
    print(f"è®€å– links.json æ™‚ç™¼ç”Ÿç·¨ç¢¼éŒ¯èª¤ï¼š{e}")
    type_links = {}

# è¼‰å…¥é…ç®¡è©¦å£“è¦ç¯„ JSON
try:
    with open("piping_specification.json", "r", encoding="utf-8") as f:
        piping_specification = json.load(f)
except FileNotFoundError:
    piping_specification = {}
    print("âŒ ç„¡æ³•æ‰¾åˆ°é…ç®¡è¦ç¯„ JSON æª”æ¡ˆã€‚")

try:
    with open("piping_heat_treatment.json", "r", encoding="utf-8") as f:
        piping_heat_treatment = json.load(f)
except FileNotFoundError:
    piping_heat_treatment = {}
    print("âŒ ç„¡æ³•æ‰¾åˆ°ç†±è™•ç†è¦ç¯„ JSON æª”æ¡ˆã€‚")

#å•é¡Œä¸­æ–‡è½‰è‹±æ–‡
def translate_to_english(query):
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "è«‹å°‡ä¸‹é¢çš„ä¸­æ–‡å·¥ç¨‹å•é¡Œç¿»è­¯ç‚ºç°¡æ½”ç²¾ç¢ºçš„è‹±æ–‡ï¼Œä¾›è³‡æ–™æ¯”å°ä½¿ç”¨ã€‚"},
            {"role": "user", "content": query}
        ],
        temperature=0.2
    )
    return response.choices[0].message.content.strip()


""" def search_piping_spec(question, spec_data, keywords):
    question_cleaned = re.sub(r"\s+", "", question).lower()
    
    matched_sections = []
    matched_titles = []
    total_matches = 0

    for chapter, data in spec_data.items():
        title = data.get("title", "")
        content = data.get("content", {})

        chapter_matched = any(keyword in title.lower() for keyword in keywords)

        if not chapter_matched:
            for sec_num, sec_text in content.items():
                sec_text_clean = re.sub(r"\s+", "", sec_text).lower()
                if question_cleaned in sec_text_clean:
                    chapter_matched = True
                    break

        if chapter_matched:
            matched_sections.append(f"ç¬¬{chapter}ç«  {title}")
            matched_titles.append(f"ç¬¬{chapter}ç«  {title}")
            total_matches += 1

            sorted_content = sorted(content.items(), key=lambda x: x[0])
            for sec_num, sec_text in sorted_content:
                matched_sections.append(f"{sec_num} {sec_text}")
                matched_titles.append(f"ç¬¬{chapter}ç«  {title} - {sec_num}")
                total_matches += 1

    if matched_sections:
        summary = "\n".join(matched_sections)
        return summary, matched_titles, total_matches

    return "", [], 0 """

def search_piping_spec(question, spec_data, keywords):
    question_cleaned = re.sub(r"\s+", "", question).lower()
    
    matched_summaries = []
    matched_details = {}
    total_matches = 0

    for chapter, data in spec_data.items():
        title = data.get("title", "")
        content = data.get("content", {})

        for sec_num, sec_text in content.items():
            text_clean = re.sub(r"\s+", "", sec_text).lower()
            if any(kw in text_clean for kw in keywords) or question_cleaned in text_clean:
                key = f"ç¬¬{chapter}ç«  {title} - {sec_num}"
                matched_summaries.append(key)
                matched_details[key] = sec_text
                total_matches += 1

    if matched_summaries:
        summary = "\n".join([f"{i+1}. {s}" for i, s in enumerate(matched_summaries)])
        return summary, matched_details, total_matches

    return "æŸ¥ç„¡ç›¸é—œå…§å®¹ã€‚", {}, 0


""" # def generate_spec_reply(user_query, spec_data, spec_type_desc):
#     keywords = {"è¦ç¯„", "è³‡æ–™", "æ¨™æº–åœ–", "æŸ¥è©¢", "æˆ‘è¦æŸ¥", "æŸ¥"}  # å®šç¾©é—œéµå­—
#     summary, matched_titles, total_matches = search_piping_spec(user_query, spec_data, keywords)
#     if total_matches == 0:
#         english_query = translate_to_english(user_query)  # ç¿»è­¯æˆè‹±æ–‡
#         summary, matched_titles, total_matches = search_piping_spec(english_query, spec_data, keywords)

#     if total_matches > 0:
#         if len(summary) > 500:
#             reply = f"æ ¹æ“šã€Š{spec_type_desc}ã€‹ï¼Œæ‰¾åˆ°ç›¸é—œå…§å®¹ï¼ˆå·²æˆªå–ï¼‰ï¼š\n{summary[:500]}...\nğŸ”” å…§å®¹éé•·ï¼Œè«‹æŸ¥é–±å®Œæ•´è¦ç¯„ã€‚"
#         else:
#             reply = f"æ ¹æ“šã€Š{spec_type_desc}ã€‹ï¼Œæ‰¾åˆ°ç›¸é—œå…§å®¹ï¼š\n{summary}"
#     else:
#         try:
#             print("ğŸ” å‘¼å« GPT å›ç­”...")
#             response = client.chat.completions.create(
#                 model="gpt-3.5-turbo",
#                 messages=[
#                     {"role": "system", "content": "ä½ æ˜¯é…ç®¡è¨­è¨ˆå°ˆå®¶ï¼Œåªå›ç­”èˆ‡é…ç®¡è¦ç¯„ç›¸é—œçš„å•é¡Œã€‚"},
#                     {"role": "user", "content": user_query}
#                 ],
#                 max_tokens=500,
#                 temperature=0.2,
#                 top_p=0.8
#             )
#             reply = response.choices[0].message.content.strip()
#         except Exception as e:
#             print("âŒ GPT å‘¼å«å¤±æ•—:", e)
#             reply = "æŠ±æ­‰ï¼Œç›®å‰ç„¡æ³•è™•ç†æ‚¨çš„è«‹æ±‚ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

#     return jsonify({
#         "fulfillmentText": reply
#     })
 """




#LINE æŒ‰éˆ•ç¨‹å¼
def payload_with_buttons(text, options):    
    return {
        "payload": {
            "line": {
                "type": "template",
                "altText": text,
                "template": {
                    "type": "buttons",
                    "text": text,
                    "actions": [
                        {"type": "message", "label": opt, "text": opt} for opt in options
                    ]
                }
            }
        }
    }

def query_download_link(category, source):
    links = {
        ("æ²¹æ¼†", "å¡‘åŒ–"): "https://tinyurl.com/yp59mpat",
        ("æ²¹æ¼†", "ä¼æ¥­"): "https://tinyurl.com/c73ajvpt\nä¿æº«å±¤ä¸‹æ–¹æ²¹æ¼†é˜²è•æš«è¡Œè¾¦æ³•\nhttps://tinyurl.com/2s3me8jh",
        ("ç®¡æ”¯æ’", "å¡‘åŒ–"): "https://tinyurl.com/5vk67ywh",
        ("ç®¡æ”¯æ’", "ä¼æ¥­"): "https://tinyurl.com/msxhmnha",
        ("é‹¼æ§‹", "å¡‘åŒ–"): "https://tinyurl.com/3tdcxe5v",
        ("é‹¼æ§‹", "ä¼æ¥­"): "https://tinyurl.com/mvb9yzhw",
        ("ä¿æº«", "ä¼æ¥­"): "https://tinyurl.com/2s4cb5cn",
        ("ä¿æº«", "å¡‘åŒ–"): "ä¿æº«è¦ç¯„è«‹åƒè€ƒä¼æ¥­è¦ç¯„\nhttps://tinyurl.com/2s4cb5cn"
    }
    return links.get((category, source), "æŸ¥ç„¡å°æ‡‰çš„ä¸‹è¼‰é€£çµ")

    # å®šç¾© categories_mapï¼Œé¡ä¼¼ actions_map çš„çµæ§‹
category_keywords = {
        "ç®¡æ”¯æ’": ["ç®¡æ”¯æ’", "æ”¯æ’", "ç®¡é“æ”¯æ’","PIPING SUPPORT","SUPPORT"],
        "æ²¹æ¼†": ["æ²¹æ¼†", "å¡—è£", "æ¼†", "æ¶‚æ–™", "painting"],
        "ä¿æº«": ["ä¿æº«", "éš”ç†±", "ç†±ä¿", "éš”ç†±ä¿æº«"],
        "é‹¼æ§‹": ["é‹¼æ§‹", "é‹¼çµæ§‹", "çµæ§‹é‹¼", "é‹¼æ¶", "çµæ§‹", "çµæ§‹é«”",
            "é‹¼æ¿", "é‹¼éµæ¿", "é‹¼æ¢", "é‹¼æ¨‘", "é‹¼çµæ§‹è¦ç¯„", "é‹¼æ§‹è¦ç¯„", "çµæ§‹è¨­è¨ˆè¦ç¯„"],
    } 
action_keywords = {
    "è©¢å•å…§å®¹": ["æŸ¥è©¢", "æŸ¥", "è©¢å•", "æ‰¾"],
    "ä¸‹è¼‰": ["ä¸‹è¼‰", "çµ¦æˆ‘", "æä¾›"],}
sources = ["ä¼æ¥­", "å¡‘åŒ–"]
categories_map = {k: v for v, keys in category_keywords.items() for k in keys}
actions_map = {k: v for v, keys in action_keywords.items() for k in keys}


def extract_from_query(text):
    found = {"category": "", "source": "", "action": ""}

        # æª¢æŸ¥æ˜¯å¦æœ‰åŒ¹é…çš„ category
    for keyword, category in categories_map.items():
        if keyword in text:
            found["category"] = category
            break
    for s in sources:
        if s in text:
            found["source"] = s
            break
    if any(word in text for word in action_keywords["ä¸‹è¼‰"]):
        found["action"] = "ä¸‹è¼‰"
    elif any(word in text for word in action_keywords["è©¢å•å…§å®¹"]):
        found["action"] = "è©¢å•å…§å®¹"

    return found
       # è®€å– context ä¸­çš„åƒæ•¸

@app.route("/webhook", methods=["POST"])
def webhook():
    req = request.get_json()
    if not isinstance(req, dict):
        print(f"âŒ éŒ¯èª¤ï¼šreq ä¸æ˜¯å­—å…¸ï¼Œè€Œæ˜¯ {type(req)}")
        return jsonify({"fulfillmentText": "è«‹æ±‚æ ¼å¼éŒ¯èª¤ï¼Œè«‹ç¢ºä¿ Content-Type ç‚º application/jsonã€‚"}) 

    query_result = req.get("queryResult", {})
    user_query = query_result.get("queryText", "")
    session = req.get("session", "")
    intent = req.get("queryResult", {}).get("intent", {}).get("displayName", "")

    # è®€å– context ä¸­çš„åƒæ•¸
    context_params = {}
    for context in req.get("queryResult", {}).get("outputContexts", []):
        if "spec-context" in context.get("name", ""):
            context_params = context.get("parameters", {})

    def output_context(params):
        if not params or params.get("await_spec_selection") is False:
            # æ¸…é™¤ä¸Šä¸‹æ–‡
            return [{
                "name": f"{session}/contexts/spec-context",
                "lifespanCount": 0,  # è¨­ç½® lifespanCount ç‚º 0 æ¸…é™¤ä¸Šä¸‹æ–‡
                "parameters": {}
            }]
        else:
            # ä¿ç•™ä¸Šä¸‹æ–‡
            return [{
                "name": f"{session}/contexts/spec-context",
                "lifespanCount": 5,  # è¨­ç½®ä¸Šä¸‹æ–‡çš„æœ‰æ•ˆæœŸ
                "parameters": params
            }]
   
    def generate_spec_reply(user_query, spec_data, spec_type_desc):
        keywords = {"è¦ç¯„", "è³‡æ–™", "æ¨™æº–åœ–", "æŸ¥è©¢", "æˆ‘è¦æŸ¥", "æŸ¥"}

        summary, matched_details, total_matches = search_piping_spec(user_query, spec_data, keywords)

        if total_matches == 0:
            english_query = translate_to_english(user_query)
            summary, matched_details, total_matches = search_piping_spec(english_query, spec_data, keywords)

        if total_matches > 0:
            reply = f"æ ¹æ“šã€Š{spec_type_desc}ã€‹ï¼Œæ‰¾åˆ° {total_matches} ç­†ç›¸é—œå…§å®¹ï¼š\n{summary}\nè«‹è¼¸å…¥å°æ‡‰çš„é …ç›®ç·¨è™ŸæŸ¥çœ‹è©³ç´°å…§å®¹ï¼ˆä¾‹å¦‚è¼¸å…¥ 1ï¼‰"
            
            # å›å‚³ matched_detailsï¼ˆå¯åºåˆ—åŒ–ï¼‰å­˜åœ¨ context ä¸­
            return jsonify({
                "fulfillmentText": reply,
                "outputContexts": output_context({
                    "await_spec_selection": True,
                    "spec_options": list(matched_details.items())  # å‚³æˆ list æ‰èƒ½åºåˆ—åŒ–æˆ JSON
                })
            })
        else:
            # ğŸ” fallback to GPT
            try:
                print("ğŸ” å‘¼å« GPT å›ç­”...")
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯é…ç®¡è¨­è¨ˆå°ˆå®¶ï¼Œåªå›ç­”èˆ‡é…ç®¡è¦ç¯„ç›¸é—œçš„å•é¡Œã€‚"},
                        {"role": "user", "content": user_query}
                    ],
                    max_tokens=500,
                    temperature=0.2,
                    top_p=0.8
                )
                reply = response.choices[0].message.content.strip()
            except Exception as e:
                print("âŒ GPT å‘¼å«å¤±æ•—:", e)
                reply = "æŠ±æ­‰ï¼Œç›®å‰ç„¡æ³•è™•ç†æ‚¨çš„è«‹æ±‚ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

            return jsonify({
                "fulfillmentText": reply
            })
    
    if context_params.get("await_spec_selection"):
        user_choice = user_query.strip()
        spec_items = context_params.get("spec_options", [])

        if not spec_items:
            # å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²’æœ‰é¸é …ï¼Œæ¸…é™¤ä¸Šä¸‹æ–‡ä¸¦é€€å‡º
            return jsonify({
                "fulfillmentText": "ä¸Šä¸‹æ–‡å·²éæœŸï¼Œè«‹é‡æ–°æŸ¥è©¢ã€‚",
                "outputContexts": output_context({})
            })

        print(f"ğŸ” Debug: user_choice={user_choice}, spec_items={spec_items}")

        if user_choice.isdigit():
            index = int(user_choice) - 1
            if 0 <= index < len(spec_items):
                title, content = spec_items[index]

                # æ¸…é™¤ä¸Šä¸‹æ–‡
                return jsonify({
                    "fulfillmentText": f"ğŸ“˜ æ‚¨é¸æ“‡çš„æ˜¯ï¼š{title}\nå…§å®¹å¦‚ä¸‹ï¼š\n{content}",
                    "outputContexts": output_context({})  # æ¸…é™¤ä¸Šä¸‹æ–‡
                })
            else:
                return jsonify({
                    "fulfillmentText": f"è«‹è¼¸å…¥æœ‰æ•ˆçš„æ•¸å­—ï¼ˆä¾‹å¦‚ 1~{len(spec_items)}ï¼‰"
                })
        else:
            return jsonify({
                "fulfillmentText": "è«‹è¼¸å…¥é …ç›®ç·¨è™Ÿï¼ˆä¾‹å¦‚ 1 æˆ– 2ï¼‰ï¼Œä»¥æŸ¥çœ‹è©³ç´°å…§å®¹ã€‚"
            })
    if intent == "User Selects Spec Item":
        user_choice = user_query.strip()
        spec_items = context_params.get("spec_options", [])

        if not spec_items:
            return jsonify({
                "fulfillmentText": "ç›®å‰æ²’æœ‰å¯ä¾›é¸æ“‡çš„é …ç›®ï¼Œè«‹å…ˆæå‡ºæŸ¥è©¢ã€‚"
            })

        if user_choice.isdigit():
            index = int(user_choice) - 1
            if 0 <= index < len(spec_items):
                title, content = spec_items[index]
                return jsonify({
                    "fulfillmentText": f"ğŸ“˜ æ‚¨é¸æ“‡çš„æ˜¯ï¼š{title}\nå…§å®¹å¦‚ä¸‹ï¼š\n{content}",
                    "outputContexts": output_context({})  # âœ… æ¸…é™¤ context
                })
            else:
                return jsonify({
                    "fulfillmentText": f"è«‹è¼¸å…¥æœ‰æ•ˆçš„æ•¸å­—ï¼ˆä¾‹å¦‚ 1~{len(spec_items)}ï¼‰"
                })
        else:
            return jsonify({
                "fulfillmentText": "è«‹è¼¸å…¥æœ‰æ•ˆçš„é …ç›®ç·¨è™Ÿï¼Œä¾‹å¦‚ 1 æˆ– 2ã€‚"
            })        
    elif intent == "è©¢å•ç†±è™•ç†è¦ç¯„":
        print(f"ğŸ” Debugç†±è™•ç†: intent={intent}, user_query={user_query}, context_params={context_params}")
        spec_reply = generate_spec_reply(user_query, piping_heat_treatment, "è©¢å•ç†±è™•ç†è¦ç¯„")
        return jsonify({
            "fulfillmentText": spec_reply.get_json()["fulfillmentText"],
            "outputContexts": output_context({
                "await_heat_question": True,
                "await_spec_selection": True
            })
        })
    elif intent == "æŸ¥è©¢è¦ç¯„2":
        # çµ±ä¸€å–å¾—åƒæ•¸ï¼šå„ªå…ˆå¾ query æŠ½å‡ºï¼Œå¦å‰‡ä½¿ç”¨ context ä¸­å€¼
        extracted_data = extract_from_query(user_query)
        category = extracted_data.get("category", context_params.get("category", ""))
        source = extracted_data.get("source", context_params.get("source", ""))
        action = extracted_data.get("action", context_params.get("action", ""))

        # æª¢æŸ¥æ˜¯å¦æåˆ° TYPE ç·¨è™Ÿ
        match = re.search(r"(?:TY(?:PE)?)[-\s]*0*(\d{1,3}[A-Z]?)", user_query.upper())
        if match:
            type_id = match.group(1)
            # åˆ¤æ–·æ˜¯å¦æœ‰è‹±æ–‡å­—å°¾
            if type_id[-1].isalpha():
                type_key = f"TYPE{type_id[:-1].zfill(2)}{type_id[-1]}"
            else:
                type_key = f"TYPE{type_id.zfill(2)}"

            if type_key in type_links:
                link = type_links[type_key]
                return jsonify({
                    "fulfillmentText": f"é€™æ˜¯ç®¡æ”¯æ’è¦ç¯„ï¼ˆå¡‘åŒ–ï¼‰{type_key} çš„ä¸‹è¼‰é€£çµï¼š\n{link}"
                })
            else:
                return jsonify({
                    "fulfillmentText": f"æ‰¾ä¸åˆ° {type_key} çš„å°æ‡‰é€£çµï¼Œè«‹ç¢ºèªæ˜¯å¦è¼¸å…¥æ­£ç¢ºã€‚"
                })
            
        print(f"ğŸ§© æŠ½å–çµæœ: category={category}, source={source}, action={action}, intent={intent}")  
        
        # âœ… åŠ å…¥è‡ªå‹•ä¸‹è¼‰æ¢ä»¶
        if action == "ä¸‹è¼‰" and category and source:
            link = query_download_link(category, source)
            return jsonify({
                "fulfillmentText": f"é€™æ˜¯ {category}ï¼ˆ{source}ï¼‰è¦ç¯„çš„ä¸‹è¼‰é€£çµï¼š\n{link}",
                "outputContexts": output_context({"category": category, "source": ""})  # æ¸…é™¤ source
            })

        keywords = {"è¦ç¯„", "è³‡æ–™", "æ¨™æº–åœ–", "æŸ¥è©¢", "æˆ‘è¦æŸ¥", "æŸ¥"}
        if any(k in user_query for k in keywords):
            if not category:
                print(f"ğŸ” Debug: category={category}, source={source}, action={action}")
                return jsonify({
                    "fulfillmentMessages": [payload_with_buttons("è«‹é¸æ“‡è¦ç¯„é¡åˆ¥", ["æŸ¥ç®¡æ”¯æ’", "æŸ¥æ²¹æ¼†", "æŸ¥é‹¼æ§‹", "æŸ¥ä¿æº«"])],
                    "outputContexts": [{
                        "name": f"{session}/contexts/spec-context",
                        "lifespanCount": 5,
                        "parameters": {"source": source, "action": action}
                    }]
                })
            elif not source:
                return jsonify({
                    "fulfillmentMessages": [payload_with_buttons(f"{category}ï¼šè«‹é¸æ“‡ä¾†æºé¡å‹", ["ä¼æ¥­", "å¡‘åŒ–"])],
                    "outputContexts": [{
                        "name": f"{session}/contexts/spec-context",
                        "lifespanCount": 5,
                        "parameters": {"category": category, "action": action}
                    }]
                })
            else:
                return jsonify({
                    "fulfillmentMessages": [
                        payload_with_buttons(
                            f"{category}ï¼ˆ{user_query}ï¼‰ï¼šè«‹é¸æ“‡ä¸‹ä¸€æ­¥",
                            [f"ä¸‹è¼‰{category}ï¼ˆ{user_query}ï¼‰", "è©¢å•å…§å®¹"]
                        )
                    ],
                    "outputContexts": [{
                        "name": f"{session}/contexts/spec-context",
                        "lifespanCount": 5,
                        "parameters": {"category": category, "source": source}
                    }]  
                })
        if user_query in ["ä¼æ¥­", "å¡‘åŒ–"]:
            # å¾ä¸Šä¸‹æ–‡ä¸­æå– category å’Œ action
            remembered_category = context_params.get("category", "")
            remembered_action = context_params.get("action", "")
            
            print(f"ğŸ” Debug: remembered_category={remembered_category}, remembered_action={remembered_action}, user_query={user_query}")
            
            if remembered_category:
                if remembered_action == "ä¸‹è¼‰":
                    link = query_download_link(remembered_category, user_query)
                    return jsonify({
                        "fulfillmentText": f"é€™æ˜¯ {remembered_category}ï¼ˆ{user_query}ï¼‰è¦ç¯„çš„ä¸‹è¼‰é€£çµï¼š\n{link}",
                        "outputContexts": [{
                            "name": f"{session}/contexts/spec-context",
                            "lifespanCount": 5,
                            "parameters": {
                                "category": remembered_category,
                                "source": user_query,
                                "action": remembered_action
                            }
                        }]
                    })
                else:
                    return jsonify({
                        "fulfillmentMessages": [
                            payload_with_buttons(
                                f"{remembered_category}ï¼ˆ{user_query}ï¼‰ï¼šè«‹é¸æ“‡ä¸‹ä¸€æ­¥",
                                [f"ä¸‹è¼‰{remembered_category}ï¼ˆ{user_query}ï¼‰", "è©¢å•å…§å®¹"]
                            )
                        ],
                        "outputContexts": [{
                            "name": f"{session}/contexts/spec-context",
                            "lifespanCount": 5,
                            "parameters": {
                                "category": remembered_category,
                                "source": user_query,
                                "action": remembered_action
                            }
                        }]
                    })
            else:
                return jsonify({
                    "fulfillmentMessages": [payload_with_buttons("è«‹é¸æ“‡è¦ç¯„é¡åˆ¥", ["ç®¡æ”¯æ’", "æ²¹æ¼†", "é‹¼æ§‹", "ä¿æº«"])],
                    "outputContexts": output_context({"source": user_query, "action": remembered_action})
                })


        if user_query == "è©¢å•å…§å®¹":
            # æ¸…é™¤ source
                return jsonify({
                    "fulfillmentText": "è«‹å•æ‚¨æƒ³è©¢å•å“ªæ®µè¦ç¯„å…§å®¹ï¼Ÿä¾‹å¦‚ï¼šæ¸¬è©¦ã€æ¸…æ´—ã€å£“åŠ›ç­‰ã€‚",
                    "outputContexts": output_context({"category": category, "source": ""})  # æ¸…é™¤ source
                })  
        
        return jsonify({
        "fulfillmentMessages": [payload_with_buttons("è«‹é¸æ“‡è¦ç¯„é¡åˆ¥3333", ["æŸ¥è©¢ç®¡æ”¯æ’", "æŸ¥è©¢æ²¹æ¼†", "æŸ¥è©¢é‹¼æ§‹", "æŸ¥è©¢ä¿æº«"])],
        "outputContexts": output_context({})
    })

    elif intent == "è©¢å•ç®¡ç·šç­‰ç´šå•é¡Œå›ç­”":
        try:
            print("ğŸ’¬ ç”± GPT å›ç­”è¦ç¯„å…§å®¹...")
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",  # å»ºè­°ä½¿ç”¨ gpt-4 æˆ– gpt-4-turbo
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯é…ç®¡è¨­è¨ˆå°ˆå®¶ï¼Œåªå›ç­”èˆ‡å·¥ç¨‹è¦ç¯„ã€æ¨™æº–åœ–æˆ–æ–½å·¥æ¨™æº–ç›¸é—œçš„å•é¡Œï¼Œè«‹æ ¹æ“šä½¿ç”¨è€…çš„å•é¡Œæä¾›æ¸…æ¥šç°¡æ½”çš„å›ç­”ã€‚"},
                    {"role": "user", "content": user_query}
                ],
                max_tokens=500,
                temperature=0.2,
                top_p=0.8
            )
            reply = response.choices[0].message.content.strip()
            return jsonify({
            "fulfillmentText": reply,
            "outputContexts": output_context({"await_pipeclass_question": True})
        })
        except Exception as e:
            print("âŒ GPT å‘¼å«å¤±æ•—:", e)
            reply = "æŠ±æ­‰ï¼Œç›®å‰ç„¡æ³•è™•ç†æ‚¨çš„è«‹æ±‚ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

        return jsonify({
            "fulfillmentText": reply,
            "outputContexts": output_context({"await_pipeclass_question": True})
        })     
    


    elif intent == "Default Fallback Intent":
        if context_params.get("await_spec_selection") :#and user_query.strip().isdigit():
            print(f"ğŸ” Debug: user_choice={user_choice}, spec_items={spec_items}")
            # âœ… æ¨¡æ“¬è§¸ç™¼ User Selects Spec Item intent
            user_choice = user_query.strip()
            spec_items = context_params.get("spec_options", [])
            index = int(user_choice) - 1
            if 0 <= index < len(spec_items):
                title, content = spec_items[index]
                return jsonify({
                    "fulfillmentText": f"ğŸ“˜ æ‚¨é¸æ“‡çš„æ˜¯ï¼š{title}\nå…§å®¹å¦‚ä¸‹ï¼š\n{content}",
                    "outputContexts": output_context({})
                })
            else:
                return jsonify({
                    "fulfillmentText": f"è«‹è¼¸å…¥æœ‰æ•ˆçš„æ•¸å­—ï¼ˆä¾‹å¦‚ 1~{len(spec_items)}ï¼‰",
                    "outputContexts": output_context({"await_spec_selection": True})
                })
       # ğŸ” è™•ç†ç†±è™•ç†å¾ŒçºŒå•é¡Œ
        elif context_params.get("await_heat_question"):
            print("ğŸ”„ é‡æ–°è·¯ç”±åˆ°ç†±è™•ç†è¦ç¯„")
            return generate_spec_reply(user_query, piping_heat_treatment, "è©¢å•ç†±è™•ç†è¦ç¯„")

        # ğŸ” è™•ç†å…¶ä»–è¦ç¯„å•é¡Œ
        elif context_params.get("await_pipeclass_question"):
            try:
                print("ğŸ’¬ ç”± GPT å›ç­”è¦ç¯„å…§å®¹...")
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯é…ç®¡è¨­è¨ˆå°ˆå®¶ï¼Œåªå›ç­”èˆ‡å·¥ç¨‹è¦ç¯„ã€æ¨™æº–åœ–æˆ–æ–½å·¥æ¨™æº–ç›¸é—œçš„å•é¡Œã€‚"},
                        {"role": "user", "content": user_query}
                    ],
                    max_tokens=500,
                    temperature=0.2,
                    top_p=0.8
                )
                reply = response.choices[0].message.content.strip()
            except Exception as e:
                print("âŒ GPT å‘¼å«å¤±æ•—:", e)
                reply = "æŠ±æ­‰ï¼Œç›®å‰ç„¡æ³•è™•ç†æ‚¨çš„è«‹æ±‚ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

            return jsonify({
                "fulfillmentText": reply
            })   
 
    else: 
        return generate_spec_reply(user_query, piping_specification, "ä¼æ¥­é…ç®¡å…±åŒè¦ç¯„")

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    app.run(host="0.0.0.0", port=port)

# (Removed invalid Python code)ngrok http 5000